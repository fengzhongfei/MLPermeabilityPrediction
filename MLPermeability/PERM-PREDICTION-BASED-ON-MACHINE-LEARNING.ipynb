{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a7b72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score#R square\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from boruta import BorutaPy\n",
    "from ngboost.ngboost import NGBoost\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.scores import MLE\n",
    "from ngboost.scores import CRPS\n",
    "from ngboost import NGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from mealpy.utils.visualize import *\n",
    "from mealpy.bio_based import BBO, EOA, IWO, SBO, SMA, TPO, VCS, WHO\n",
    "from mealpy.evolutionary_based import CRO, DE, EP, ES, FPA, GA, MA\n",
    "from mealpy.human_based import BRO, BSO, CA, CHIO, FBIO, GSKA, ICA, LCO, QSA, SARO, SSDO, TLO\n",
    "from mealpy.math_based import AOA, CGO, GBO, HC, SCA\n",
    "from mealpy.music_based import HS\n",
    "from mealpy.physics_based import ArchOA, ASO, EFO, EO, HGSO, MVO, NRO, SA, TWO, WDO\n",
    "from mealpy.system_based import AEO, GCO, WCA\n",
    "from mealpy.swarm_based import ABC, ACOR, ALO, AO, BA, BeesA, BES, BFO, BSA, COA, CSA, CSO, DO, EHO, FA, FFA, FOA, GOA, GWO, HGS\n",
    "from mealpy.swarm_based import HHO, JA, MFO, MRFO, MSA, NMRA, PFA, PSO, SFO, SHO, SLO, SRSR, SSA, SSO, SSpiderA, SSpiderO, WOA\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost as cat\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost as cat\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from ngboost.scores import LogScore, CRPScore\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a0c6d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c7052",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('MLCORE_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282864b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1451d03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba84612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b400c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# Load the Times New Roman font\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# From CSV file\n",
    "def read_data_from_csv(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    return data\n",
    "\n",
    "# Plot histograms in subplots\n",
    "def plot_histograms_in_subplots(data):\n",
    "    num_rows = 4\n",
    "    num_cols = 4\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
    "    variables = data.columns.tolist()\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            index = i * num_cols + j\n",
    "            if index < len(variables):\n",
    "                variable_name = variables[index]\n",
    "                axes[i, j].hist(data[variable_name],  bins=20, alpha=0.7, color='deepskyblue',edgecolor='black')\n",
    "                axes[i, j].tick_params(axis='both', labelsize=12)\n",
    "                # Move the variable name below the subplot\n",
    "                axes[i, j].text(0.5, -0.2, variable_name, va='center', ha='center', transform=axes[i, j].transAxes, fontproperties=font_prop)\n",
    "            else:\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('datahist.jpg',dpi=1500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = \"MLCORE_3.csv\"   # Replace with your CSV file path\n",
    "    data = read_data_from_csv(csv_file_path)\n",
    "    plot_histograms_in_subplots(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95186b5b",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d60e68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataframe = df\n",
    "dataframe['PERM1'] = pd.cut(dataframe['PERM'],\n",
    "                    bins=[-2.,-1.,0.,1.,2.,3.],\n",
    "                    labels=[1,2,3,4,5])\n",
    "dataframe['PERM1'].hist()\n",
    "print(pd.value_counts(dataframe['PERM1'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f19c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.3,  random_state=42) \n",
    "for train_index, test_index in split.split(dataframe, dataframe['PERM1']):\n",
    "    strat_train_set = dataframe.iloc[train_index]      \n",
    "    strat_test_set = dataframe.iloc[test_index]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03287c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = strat_train_set.copy()\n",
    "test_set = strat_test_set.copy()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3b55a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train_set1 = train_set.drop(['DEPTH','BIT','CAL'],axis=1)\n",
    "#test_set1 = test_set.drop(['DEPTH','BIT','CAL'],axis=1)\n",
    "train_set1 = train_set\n",
    "test_set1 = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf9fc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e2a43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_set1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c122e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set11 = train_set1.values\n",
    "train_set11 = train_set11.astype('float32')\n",
    "test_set11 = test_set1.values\n",
    "test_set11 = test_set11.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67daac1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train_set = train_set.values\n",
    "X_train = train_set11[:,0:16]\n",
    "#y_por_train = train_set11[:,16]\n",
    "y_perm_train = train_set11[:,16]\n",
    "print(X_train.shape)\n",
    "#print(y_por_train.shape)\n",
    "print(y_perm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f3f7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#test_set = test_set.va0ues\n",
    "X_test = test_set11[:,0:16]\n",
    "#y_por_test = test_set11[:,16]\n",
    "y_perm_test = test_set11[:,16]\n",
    "print(X_test.shape)\n",
    "#print(y_por_test.shape)\n",
    "print(y_perm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ys = pd.DataFrame(X_train,columns=['DEPTH','SP', 'GR','BIT','CAL', 'CNL', 'DEN', 'DTC', 'DTS','P16H', 'P28H', 'P40H', 'A40H', 'SH','KJ','POR_LOG'])\n",
    "X_train_ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ys = pd.DataFrame(y_perm_train,columns=['PERM'])\n",
    "y_train_ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4aa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ys = pd.DataFrame(X_test,columns=['DEPTH','SP', 'GR','BIT','CAL', 'CNL', 'DEN', 'DTC', 'DTS','P16H', 'P28H', 'P40H', 'A40H', 'SH','KJ','POR_LOG'])\n",
    "X_test_ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91464bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ys = pd.DataFrame(y_perm_test,columns=['PERM'])\n",
    "y_test_ys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad1e93",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29579ac2",
   "metadata": {},
   "source": [
    "# 1. Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0deb3b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix =  train_set1.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7831d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 10))\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.yticks(fontproperties='Times New Roman', size=15,weight='bold')#\n",
    "plt.xticks(fontproperties='Times New Roman', size=15,weight='bold')\n",
    "sns.heatmap(data=corr_matrix, \n",
    "            annot=True,\n",
    "            annot_kws={\"size\":12,\"font\":'Times New Roman'},\n",
    "            square=True,\n",
    "            cmap='vlag',\n",
    "            fmt='.2f', \n",
    "            linewidths=1,\n",
    "            linecolor='w',\n",
    "            ax=ax)\n",
    "plt.savefig('Pearson correlation matrix.svg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f9dfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_pearson = X_train_ys.drop(['SP','BIT','CAL','P40H','A40H'],axis=1)\n",
    "X_train_pearson .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbccef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test_pearson = X_test_ys.drop(['SP','BIT','CAL','P40H','A40H'],axis=1)\n",
    "X_test_pearson.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0735e",
   "metadata": {},
   "source": [
    "# 2.RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f095b",
   "metadata": {},
   "source": [
    "# RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731dffb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfe_xg = xgb.XGBRegressor(random_state = 42)\n",
    "rfecv_xg = RFECV(estimator=rfe_xg, step=1,min_features_to_select=1, cv=5, scoring='r2',n_jobs=-1,importance_getter='auto')\n",
    "rfecv_xg.fit(X_train_ys,y_train_ys)\n",
    "print('Optimal number of features: {}'.format(rfecv_xg.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7615808",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.xlabel(\"Number of features\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"R\\u00b2\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.plot(range(1, len(rfecv_xg.grid_scores_) + 1), rfecv_xg.grid_scores_, linewidth=3)\n",
    "plt.tight_layout() \n",
    "plt.savefig('RFECV-XGBoost.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216851e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_xg.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ad1ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.where(rfecv_xg.support_ == False)[0])\n",
    "X_train_hbdf1 = pd.DataFrame(X_train_ys)\n",
    "X_train_hbdf1.drop(X_train_hbdf1.columns[np.where(rfecv_xg.support_ == False)[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791360fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_xg.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e1b44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset = pd.DataFrame()\n",
    "dset['attr'] = X_train_hbdf1.columns\n",
    "dset['importance'] = rfecv_xg.estimator_.feature_importances_\n",
    "dset = dset.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838682a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a5ee4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.barh(y=dset['attr'], width=dset['importance'], color='b')\n",
    "plt.xlabel('Feature importance',fontproperties=\"Times New Roman\",fontsize=20, labelpad=20)\n",
    "plt.savefig('RFECV_XGBOOST-Feature importances.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b5300",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfe_lg = lgb.LGBMRegressor(random_state = 42)\n",
    "rfecv_lg = RFECV(estimator=rfe_lg, step=1, cv=5, scoring='r2')\n",
    "rfecv_lg.fit(X_train_ys,y_train_ys)\n",
    "print('Optimal number of features: {}'.format(rfecv_lg.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1b52e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.xlabel(\"Number of features\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"R\\u00b2\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.plot(range(1, len(rfecv_lg.grid_scores_) + 1), rfecv_lg.grid_scores_, linewidth=3)\n",
    "plt.savefig('RFECV-LightGBM.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e928d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_lg.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8af47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.where(rfecv_lg.support_ == False)[0])\n",
    "X_train_hbdf1 = pd.DataFrame(X_train_ys)\n",
    "X_train_hbdf1.drop(X_train_hbdf1.columns[np.where(rfecv_lg.support_ == False)[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318ec25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_lg.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b185a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset = pd.DataFrame()\n",
    "dset['attr'] = X_train_hbdf1.columns\n",
    "dset['importance'] = rfecv_lg.estimator_.feature_importances_\n",
    "dset = dset.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b54f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be923609",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.barh(y=dset['attr'], width=dset['importance'], color='b')\n",
    "plt.xlabel('Feature importance',fontproperties=\"Times New Roman\",fontsize=20, labelpad=20)\n",
    "plt.savefig('RFECV_LightGBM-Feature importances.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210116b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfe_rf =RandomForestRegressor(\n",
    "        n_estimators = 500,  \n",
    "        max_depth = 10,     \n",
    "        random_state = 42)\n",
    "rfecv_rf = RFECV(estimator=rfe_rf, step=1, cv=5, scoring='r2')\n",
    "rfecv_rf.fit(X_train_ys,y_train_ys)\n",
    "print('Optimal number of features: {}'.format(rfecv_rf.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267edb6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.xlabel(\"Number of features\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"R\\u00b2\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.plot(range(1, len(rfecv_rf.grid_scores_) + 1), rfecv_rf.grid_scores_, linewidth=3)\n",
    "plt.savefig('RFECV-RF.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7ecec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_rf.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4ea1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.where(rfecv_rf.support_ == False)[0])\n",
    "X_train_hbdf1 = pd.DataFrame(X_train_ys)\n",
    "X_train_hbdf1.drop(X_train_hbdf1.columns[np.where(rfecv_rf.support_ == False)[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d4393",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_xg.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f084e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset = pd.DataFrame()\n",
    "dset['attr'] = X_train_hbdf1.columns\n",
    "dset['importance'] = rfecv_rf.estimator_.feature_importances_\n",
    "dset = dset.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5eb7d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb8a1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.barh(y=dset['attr'], width=dset['importance'], color='b')\n",
    "plt.xlabel('Feature importance',fontproperties=\"Times New Roman\",fontsize=20, labelpad=20)\n",
    "plt.savefig('RFECV_RF-Feature importances.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9518e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfe_cat = cat.CatBoostRegressor(random_state = 42)\n",
    "rfecv_cat = RFECV(estimator=rfe_cat, step=1, cv=5, scoring='r2')\n",
    "rfecv_cat.fit(X_train_ys,y_train_ys)\n",
    "print('Optimal number of features: {}'.format(rfecv_cat.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d867c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.xlabel(\"Number of features\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"R\\u00b2\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.plot(range(1, len(rfecv_cat.grid_scores_) + 1), rfecv_cat.grid_scores_, linewidth=3)\n",
    "plt.savefig('RFECV-CATBoost.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e602465",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_cat.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b179d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.where(rfecv_cat.support_ == False)[0])\n",
    "X_train_hbdf1 = pd.DataFrame(X_train_ys)\n",
    "X_train_hbdf1.drop(X_train_hbdf1.columns[np.where(rfecv_cat.support_ == False)[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e9469",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rfecv_cat.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2f086",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset = pd.DataFrame()\n",
    "dset['attr'] = X_train_hbdf1.columns\n",
    "dset['importance'] = rfecv_cat.estimator_.feature_importances_\n",
    "dset = dset.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0c41d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd251f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = 6,4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.barh(y=dset['attr'], width=dset['importance'], color='b')\n",
    "plt.xlabel('Feature importance',fontproperties=\"Times New Roman\",fontsize=20, labelpad=20)\n",
    "plt.savefig('RFECV_CATBoost-Feature importances.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5465d",
   "metadata": {},
   "source": [
    "# Boruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986703d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from BorutaShap import BorutaShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec39a72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(random_state = 42)\n",
    "\n",
    "Feature_Selector = BorutaShap(model = xgb_reg, \n",
    "                              importance_measure='shap', \n",
    "                              classification=False)\n",
    "Feature_Selector.fit(X=X_train_ys, y= y_perm_train, n_trials=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849273cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Feature_Selector.TentativeRoughFix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2065b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "Feature_Selector.plot(X_size=10, figsize=(8,6),y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9386a18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subset = Feature_Selector.Subset()\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310e09e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgb_reg = lgb.LGBMRegressor(random_state = 42)\n",
    "\n",
    "Feature_Selector_lgb = BorutaShap(model = lgb_reg, \n",
    "                              importance_measure='shap', \n",
    "                              classification=False)\n",
    "Feature_Selector_lgb.fit(X=X_train_ys, y= y_perm_train, n_trials=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f05954",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Feature_Selector_lgb.TentativeRoughFix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f359a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "Feature_Selector_lgb.plot(X_size=10, figsize=(8,6),y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05159f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subset_lgb = Feature_Selector_lgb.Subset()\n",
    "subset_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564b9d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_reg =  RandomForestRegressor(\n",
    "        n_estimators = 50,  \n",
    "        max_depth = 10,     \n",
    "        random_state = 42)\n",
    "Feature_Selector_rf = BorutaShap(model = rf_reg, \n",
    "                              importance_measure='shap', \n",
    "                              classification=False)\n",
    "Feature_Selector_rf.fit(X=X_train_ys, y= y_perm_train, n_trials=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73878199",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Feature_Selector_rf.TentativeRoughFix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c99ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "Feature_Selector_rf.plot(X_size=10, figsize=(8,6),y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cfc1fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subset_rf = Feature_Selector_rf.Subset()\n",
    "subset_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984dbd4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_reg =  cat.CatBoostRegressor(random_state = 42)\n",
    "Feature_Selector_cat = BorutaShap(model = cat_reg , \n",
    "                              importance_measure='shap', \n",
    "                              classification=False)\n",
    "Feature_Selector_cat.fit(X=X_train_ys, y= y_perm_train, n_trials=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3b523",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Feature_Selector_cat.TentativeRoughFix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37176682",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "Feature_Selector_cat.plot(X_size=10, figsize=(8,6),y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3eb4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subset_cat = Feature_Selector_cat.Subset()\n",
    "subset_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767336f1",
   "metadata": {},
   "source": [
    "#    # Feature Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb57d20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#original dataset\n",
    "X_train_ys1 = X_train_ys\n",
    "print(X_train_ys1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1c8f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train_ys1 = y_train_ys\n",
    "print(y_train_ys1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91481b3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test_ys1 = X_test_ys\n",
    "print(X_test_ys1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f52868",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test_ys1 = y_test_ys\n",
    "print(y_test_ys1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca29970",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_train_xg = X_train_ys.drop(['BIT','DTC','DTS'],axis=1)\n",
    "X_RFE_train_xg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6fd22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_test_xg = X_test_ys.drop(['BIT','DTC','DTS'],axis=1)\n",
    "X_RFE_test_xg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ab9f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_train_lg = X_train_ys.drop(['BIT'],axis=1)\n",
    "X_RFE_train_lg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb5b03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_test_lg = X_test_ys.drop(['BIT'],axis=1)\n",
    "X_RFE_test_lg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3895d63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_train_rf = X_train_ys.drop(['BIT'],axis=1)\n",
    "X_RFE_train_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217879a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_test_rf = X_test_ys.drop(['BIT'],axis=1)\n",
    "X_RFE_test_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2c73e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_train_cat = X_train_ys.drop(['BIT','DTC','P28H'],axis=1)\n",
    "X_RFE_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bc321",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_RFE_test_cat = X_test_ys.drop(['BIT','DTC','P28H'],axis=1)\n",
    "X_RFE_test_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbd008",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_train_xg = X_train_ys.drop(['BIT','DTS','P28H'],axis=1)\n",
    "X_boruta_train_xg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43036f42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_test_xg = X_test_ys.drop(['BIT','DTS','P28H'],axis=1)\n",
    "X_boruta_test_xg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7be59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_train_lg =  X_train_ys.drop(['BIT','DTS','P28H','DTC','P40H'],axis=1)\n",
    "X_boruta_train_lg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8182e6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_test_lg = X_test_ys.drop(['BIT','DTS','P28H','DTC','P40H'],axis=1)\n",
    "X_boruta_test_lg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ce3f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_train_rf = X_train_ys.drop(['BIT','DTS'],axis=1)\n",
    "X_boruta_train_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef07c0f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_test_rf = X_test_ys.drop(['BIT','DTS'],axis=1)\n",
    "X_boruta_test_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814de6af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_train_cat = X_train_ys.drop(['CNL','P40H','P28H','BIT'],axis=1)\n",
    "X_boruta_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d361cc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_boruta_test_cat = X_test_ys.drop(['CNL','P40H','P28H','BIT'],axis=1)\n",
    "X_boruta_test_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266494f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "RF\\XGBOOST\\LIGHTGBM\\NGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a523402",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#2 RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f477d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_train_ys,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_train_ys)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_test_ys)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d08d52",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_train_pearson,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_train_pearson)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_test_pearson)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2153a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_RFE_train_xg,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_RFE_train_xg)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_RFE_test_xg)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1937dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_RFE_train_lg,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_RFE_train_lg)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_RFE_test_lg)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_RFE_train_rf,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_RFE_train_rf)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_RFE_test_rf)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_RFE_train_cat,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_RFE_train_cat)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_RFE_test_cat)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_boruta_train_xg,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_boruta_train_xg)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_boruta_test_xg)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_boruta_train_lg,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_boruta_train_lg)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_boruta_test_lg)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08966817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_boruta_train_rf,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_boruta_train_rf)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_boruta_test_rf)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_rmse_test))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a9148",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state =42) \n",
    "rf_reg.fit(X_boruta_train_cat,y_train_ys)\n",
    "y_perm_train_predict_rf = rf_reg.predict(X_boruta_train_cat)\n",
    "y_perm_test_predict_rf = rf_reg.predict(X_boruta_test_cat)\n",
    "rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_rf)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_rf)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_rmse_train))\n",
    "rf_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_rf)\n",
    "print('*  Train Score: %.4f MAE' % (rf_mae_train))\n",
    "rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_rf)\n",
    "print('*  Test Score: %.4f MAE' % (rf_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_rf))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0a153",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1ec72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_train_ys,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_train_ys)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_test_ys)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28870fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_train_pearson,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_train_pearson)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_test_pearson)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_RFE_train_xg,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_RFE_train_xg)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_RFE_test_xg)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_RFE_train_lg,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_RFE_train_lg)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_RFE_test_lg)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_RFE_train_rf,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_RFE_train_rf)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_RFE_test_rf)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_RFE_train_cat,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_RFE_train_cat)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_RFE_test_cat)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_boruta_train_xg,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_boruta_train_xg)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_boruta_test_xg)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_boruta_train_lg,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_boruta_train_lg)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_boruta_test_lg)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_boruta_train_rf,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_boruta_train_rf)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_boruta_test_rf)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xg_reg =  xgb.XGBRegressor(random_state = 42)\n",
    "xg_reg.fit(X_boruta_train_cat,y_train_ys)\n",
    "y_perm_train_predict_xg = xg_reg.predict(X_boruta_train_cat)\n",
    "y_perm_test_predict_xg = xg_reg.predict(X_boruta_test_cat)\n",
    "xg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_xg)\n",
    "xg_rmse_train = np.sqrt(xg_mse_train)\n",
    "xg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_xg)\n",
    "xg_rmse_test = np.sqrt(xg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xg_rmse_test))\n",
    "xg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_xg)\n",
    "print('*  Train Score: %.4f MAE' % (xg_mae_train))\n",
    "xg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_xg)\n",
    "print('*  Test Score: %.4f MAE' % (xg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_xg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c4ab2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#4 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e73858",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_train_ys,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_train_ys)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_test_ys)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3359d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_train_pearson,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_train_pearson)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_test_pearson)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b21b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_RFE_train_xg,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_RFE_train_xg)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_RFE_test_xg)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218347c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_RFE_train_lg,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_RFE_train_lg)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_RFE_test_lg)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112253d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_RFE_train_rf,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_RFE_train_rf)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_RFE_test_rf)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3177bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_RFE_train_cat,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_RFE_train_cat)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_RFE_test_cat)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54057d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_boruta_train_xg,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_boruta_train_xg)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_boruta_test_xg)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae272604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_boruta_train_lg,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_boruta_train_lg)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_boruta_test_lg)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_boruta_train_rf,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_boruta_train_rf)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_boruta_test_rf)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lg_reg = lgb.LGBMRegressor(random_state=42)\n",
    "lg_reg.fit(X_boruta_train_cat,y_train_ys)\n",
    "y_perm_train_predict_lg = lg_reg.predict(X_boruta_train_cat)\n",
    "y_perm_test_predict_lg = lg_reg.predict(X_boruta_test_cat)\n",
    "lg_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_lg)\n",
    "lg_rmse_train = np.sqrt(lg_mse_train)\n",
    "lg_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_lg)\n",
    "lg_rmse_test = np.sqrt(lg_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lg_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lg_rmse_test))\n",
    "lg_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_lg)\n",
    "print('*  Train Score: %.4f MAE' % (lg_mae_train))\n",
    "lg_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_lg)\n",
    "print('*  Test Score: %.4f MAE' % (lg_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_lg))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec00030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 NGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300fb51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_train_ys,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_train_ys)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_test_ys)\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_train_pearson,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_train_pearson)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_test_pearson)\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903320cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_RFE_train_xg,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_RFE_train_xg)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_RFE_test_xg)\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a037ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_RFE_train_lg,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_RFE_train_lg)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_RFE_test_lg)\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e409d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_RFE_train_rf,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_RFE_train_rf)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_RFE_test_rf)\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_RFE_train_cat,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_RFE_train_cat)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_RFE_test_cat)\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_boruta_train_xg,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_boruta_train_xg)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_boruta_test_xg)\n",
    "\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_boruta_train_lg,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_boruta_train_lg)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_boruta_test_lg)\n",
    "\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e09824",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_boruta_train_rf,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_boruta_train_rf)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_boruta_test_rf)\n",
    "\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor(random_state=42)\n",
    "ngb_reg.fit(X_boruta_train_cat,y_train_ys)\n",
    "y_perm_train_predict_ngb = ngb_reg.predict(X_boruta_train_cat)\n",
    "y_perm_test_predict_ngb = ngb_reg.predict(X_boruta_test_cat)\n",
    "\n",
    "ngb_mse_train = mean_squared_error(y_train_ys,y_perm_train_predict_ngb)\n",
    "ngb_rmse_train = np.sqrt(ngb_mse_train)\n",
    "ngb_mse_test = mean_squared_error(y_test_ys,y_perm_test_predict_ngb)\n",
    "ngb_rmse_test = np.sqrt(ngb_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ngb_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ngb_rmse_test))\n",
    "\n",
    "ngb_mae_train = mean_absolute_error(y_train_ys, y_perm_train_predict_ngb)\n",
    "print('*  Train Score: %.4f MAE' % (ngb_mae_train))\n",
    "ngb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_predict_ngb)\n",
    "print('*  Test Score: %.4f MAE' % (ngb_mae_test))\n",
    "print(\"r2 score:\", r2_score(y_train_ys, y_perm_train_predict_ngb))\n",
    "print(\"r2 score:\", r2_score(y_test_ys, y_perm_test_predict_ngb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b40c0",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.font_manager import FontProperties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aafe3ab",
   "metadata": {},
   "source": [
    "# Rondom Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f32d1",
   "metadata": {},
   "source": [
    "# RF- PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644db567",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg_PSO = RandomForestRegressor(random_state =42)\n",
    "\n",
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    #numEstim_for = [200, 4 00, 500]\n",
    "    #numEstim = np.arange(100,500,20)\n",
    "    numEstim = int(solution[0])\n",
    "    min_samples_split = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_samples_leaf=int(solution[3])\n",
    "    \n",
    "    rf_reg_PSO = RandomForestRegressor(n_estimators = numEstim,min_samples_split = min_samples_split,max_depth = max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    # Fit the model\n",
    "    rf_reg_PSO.fit(X_boruta_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_rf = rf_reg_PSO.predict(X_boruta_train_xg)\n",
    "    y_perm_test_pred_rf = rf_reg_PSO.predict(X_boruta_test_xg)\n",
    "    # Measure the performance\n",
    "    #未进行反归一化\n",
    "    \n",
    "    #calculate root mean squared error均方根误差\n",
    "    rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "    rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf)\n",
    "    rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "    rf_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_rf)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [100,    2,  2,2],\n",
    "    \"ub\": [2000, 30, 20,30],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"rf_pso.log\"\n",
    "}\n",
    "model_RF_PSO = PSO.BasePSO(problem, epoch=100, pop_size=50, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9)\n",
    "model_RF_PSO.solve()\n",
    "best_position, best_fitness = model_RF_PSO.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_RF_PSO.history.list_global_best_fit, title='Global Best Fitness', filename='RF_PSO_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_RF_PSO.history.list_current_best_fit, title='Local Best Fitness', filename='RF_PSO_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_RF_PSO.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='RF_PSO_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exp loration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_RF_PSO.history.list_exploration, model_RF_PSO.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_RF_PSO.history.list_diversity], list_legends=['RF_PSO'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_RF_PSO.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='RF_PSO_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_RF_PSO.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='RF_PSO_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a966e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_reg_PSO = RandomForestRegressor(n_estimators=100,min_samples_split=2, max_depth=20, min_samples_leaf=2,random_state=42)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "rf_reg_PSO.fit(X_boruta_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654e4f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_pso = rf_reg_PSO.predict(X_boruta_train_xg)\n",
    "y_perm_test_pred_rf_pso = rf_reg_PSO.predict(X_boruta_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b2864",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_pso = y_perm_train_pred_rf_pso.reshape(-1,1)\n",
    "y_perm_test_pred_rf_pso = y_perm_test_pred_rf_pso.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7abee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_pso_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf_pso)\n",
    "rf_pso_rmse_train = np.sqrt(rf_pso_mse_train)\n",
    "rf_pso_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf_pso)\n",
    "rf_pso_rmse_test = np.sqrt(rf_pso_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_pso_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_pso_rmse_test))\n",
    "rf_pso_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf_pso)\n",
    "print('*  Train Score: %.4f MAE' % (rf_pso_mae_train))\n",
    "rf_pso_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf_pso)\n",
    "print('*  Test Score: %.4f MAE' % (rf_pso_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_rf_pso))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_rf_pso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ca5f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_rf_pso,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.966)') \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_rf_pso,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.875)')  \n",
    "#plt.grid()  \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'  \n",
    "           , prop = font\n",
    "           , markerscale = 2\n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "#保存图片\n",
    "plt.savefig('R2-RF-PSO.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30cab6",
   "metadata": {},
   "source": [
    "# 4.4 PSO- GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0d4a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg_GA = RandomForestRegressor(random_state =42)\n",
    "\n",
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    #numEstim_for = [200, 400, 500]\n",
    "    #numEstim = np.arange(100,500,20)\n",
    "    numEstim = int(solution[0])\n",
    "    min_samples_split = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_samples_leaf=int(solution[3])\n",
    "    \n",
    "    rf_reg_GA = RandomForestRegressor(n_estimators = numEstim,min_samples_split = min_samples_split,max_depth = max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    # Fit the model\n",
    "    rf_reg_GA.fit(X_boruta_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_rf = rf_reg_GA.predict(X_boruta_train_xg)\n",
    "    y_perm_test_pred_rf = rf_reg_GA.predict(X_boruta_test_xg)\n",
    "    # Measure the performance\n",
    "    #calculate root mean squared error\n",
    "    rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "    rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf)\n",
    "    rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "    rf_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_rf)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [100,    2,  2,2],\n",
    "    \"ub\": [2000, 30, 20,30],\n",
    "    \"minmax\": \"max\",\n",
    "}\n",
    "model_RF_GA = GA.BaseGA(problem, epoch=100, pop_size=50, pc=0.95, pm=0.1, mutation_multipoints=True, mutation=\"flip\")\n",
    "model_RF_GA.solve()\n",
    "best_position, best_fitness = model_RF_GA.solve()\n",
    "print(f\" Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf23130",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_RF_GA.history.list_global_best_fit, title='Global Best Fitness', filename='RF_GA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_RF_GA.history.list_current_best_fit, title='Local Best Fitness', filename='RF_GA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_RF_GA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='RF_GA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_RF_GA.history.list_exploration, model_RF_GA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_RF_GA.history.list_diversity], list_legends=['RF_GA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_RF_GA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='RF_GA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_RF_GA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='RF_GA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014023b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_reg_GA = RandomForestRegressor(n_estimators=200,min_samples_split=4, max_depth=19, min_samples_leaf=3,random_state=42)\n",
    "# Fit the model\n",
    "rf_reg_GA.fit(X_boruta_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca0973",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_ga = rf_reg_GA.predict(X_boruta_train_xg)\n",
    "y_perm_test_pred_rf_ga = rf_reg_GA.predict(X_boruta_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e56ca3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_ga = y_perm_train_pred_rf_ga.reshape(-1,1)\n",
    "y_perm_test_pred_rf_ga = y_perm_test_pred_rf_ga.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075959c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rf_ga_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf_ga)\n",
    "rf_ga_rmse_train = np.sqrt(rf_ga_mse_train)\n",
    "rf_ga_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf_ga)\n",
    "rf_ga_rmse_test = np.sqrt(rf_ga_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_ga_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_ga_rmse_test))\n",
    "rf_ga_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf_ga)\n",
    "print('*  Train Score: %.4f MAE' % (rf_ga_mae_train))\n",
    "rf_ga_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf_ga)\n",
    "print('*  Test Score: %.4f MAE' % (rf_ga_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccf4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_rf_ga))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_rf_ga))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66b8cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_rf_ga,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.951)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_rf_ga,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.874)')  \n",
    "#plt.grid()  \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   \n",
    "           , prop = font\n",
    "           , markerscale = 2\n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-RF-GA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f326ec",
   "metadata": {},
   "source": [
    "# 4.6 RF-SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56267d2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg_SSA = RandomForestRegressor(random_state =42)\n",
    "\n",
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    #numEstim_for = [200, 400, 500]\n",
    "    #numEstim = np.arange(100,500,20)\n",
    "    numEstim = int(solution[0])\n",
    "    min_samples_split = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_samples_leaf=int(solution[3])\n",
    "    \n",
    "    rf_reg_SSA = RandomForestRegressor(n_estimators = numEstim,min_samples_split = min_samples_split,max_depth = max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    # Fit the model\n",
    "    rf_reg_SSA.fit(X_boruta_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_rf = rf_reg_SSA.predict(X_boruta_train_xg)\n",
    "    y_perm_test_pred_rf = rf_reg_SSA.predict(X_boruta_test_xg)\n",
    "    # Measure the performance\n",
    "    #未进行反归一化\n",
    "    #calculate root mean squared error均方根误差\n",
    "    rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "    rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf)\n",
    "    rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "    rf_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_rf)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [100,    2,  2,2],\n",
    "    \"ub\": [2000, 30, 20,30],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"rf_ssa.log\"\n",
    "}\n",
    "model_RF_SSA = SSA.BaseSSA(problem, epoch=100, pop_size=50, ST=0.8, PD=0.2, SD=0.1)\n",
    "model_RF_SSA.solve()\n",
    "best_position, best_fitness = model_RF_SSA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72943107",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_RF_SSA.history.list_global_best_fit, title='Global Best Fitness', filename='RF_SSA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_RF_SSA.history.list_current_best_fit, title='Local Best Fitness', filename='RF_SSA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_RF_SSA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='RF_SSA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_RF_SSA.history.list_exploration, model_RF_SSA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_RF_SSA.history.list_diversity], list_legends=['RF_SSA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_RF_SSA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='RF_SSA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_RF_SSA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='RF_SSA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99977d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_reg_SSA = RandomForestRegressor(n_estimators=1816,min_samples_split=2, max_depth=16, min_samples_leaf=2,random_state=42)\n",
    "rf_reg_SSA.fit(X_boruta_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b8aa3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_ssa = rf_reg_SSA.predict(X_boruta_train_xg)\n",
    "y_perm_test_pred_rf_ssa = rf_reg_SSA.predict(X_boruta_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b05c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_ssa = y_perm_train_pred_rf_ssa.reshape(-1,1)\n",
    "y_perm_test_pred_rf_ssa = y_perm_test_pred_rf_ssa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cde38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_ssa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf_ssa)\n",
    "rf_ssa_rmse_train = np.sqrt(rf_ssa_mse_train)\n",
    "rf_ssa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf_ssa)\n",
    "rf_ssa_rmse_test = np.sqrt(rf_ssa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_ssa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_ssa_rmse_test))\n",
    "rf_ssa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf_ssa)\n",
    "print('*  Train Score: %.4f MAE' % (rf_ssa_mae_train))\n",
    "rf_ssa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf_ssa)\n",
    "print('*  Test Score: %.4f MAE' % (rf_ssa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_rf_ssa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_rf_ssa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4314686",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_rf_ssa,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.965)') \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_rf_ssa,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.875)')  \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'  \n",
    "           , prop = font\n",
    "           , markerscale = 2#\n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "plt.savefig('R2-RF-SSA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ad2b7",
   "metadata": {},
   "source": [
    "# RF-WOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9e8c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg_WOA = RandomForestRegressor(random_state =42)\n",
    "\n",
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    #numEstim_for = [200, 400, 500]\n",
    "    #numEstim = np.arange(100,500,20)\n",
    "    numEstim = int(solution[0])\n",
    "    min_samples_split = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_samples_leaf=int(solution[3])\n",
    "    \n",
    "    rf_reg_WOA = RandomForestRegressor(n_estimators = numEstim,min_samples_split = min_samples_split,max_depth = max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    # Fit the model\n",
    "    rf_reg_WOA.fit(X_boruta_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_rf = rf_reg_WOA.predict(X_boruta_train_xg)\n",
    "    y_perm_test_pred_rf = rf_reg_WOA.predict(X_boruta_test_xg)\n",
    "    # Measure the performance\n",
    "    rf_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "    rf_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf)\n",
    "    rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "    rf_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf)\n",
    "    rf_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_rf)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [100,    2,  2,2],\n",
    "    \"ub\": [2000, 30, 20,30],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"rf_WOA.log\"\n",
    "}\n",
    "model_RF_WOA = WOA.HI_WOA(problem, epoch=100, pop_size=50, feedback_max=5)\n",
    "model_RF_WOA.solve()\n",
    "best_position, best_fitness = model_RF_WOA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_RF_WOA.history.list_global_best_fit, title='Global Best Fitness', filename='RF_WOA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_RF_WOA.history.list_current_best_fit, title='Local Best Fitness', filename='RF_WOA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_RF_WOA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='RF_WOA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_RF_WOA.history.list_exploration, model_RF_WOA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_RF_WOA.history.list_diversity], list_legends=['RF_WOA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_RF_WOA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='RF_WOA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_RF_WOA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='RF_WOA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05944378",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_reg_WOA = RandomForestRegressor(n_estimators=100,min_samples_split=2, max_depth=14, min_samples_leaf=2,random_state=42)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "rf_reg_WOA.fit(X_boruta_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863d021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_woa = rf_reg_WOA.predict(X_boruta_train_xg)\n",
    "y_perm_test_pred_rf_woa = rf_reg_WOA.predict(X_boruta_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d545440",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_rf_woa = y_perm_train_pred_rf_woa.reshape(-1,1)\n",
    "y_perm_test_pred_rf_woa = y_perm_test_pred_rf_woa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4dff5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_woa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_rf_woa)\n",
    "rf_woa_rmse_train = np.sqrt(rf_woa_mse_train)\n",
    "rf_woa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_rf_woa)\n",
    "rf_woa_rmse_test = np.sqrt(rf_woa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (rf_woa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (rf_woa_rmse_test))\n",
    "rf_woa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_rf_woa)\n",
    "print('*  Train Score: %.4f MAE' % (rf_woa_mae_train))\n",
    "rf_woa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_rf_woa)\n",
    "print('*  Test Score: %.4f MAE' % (rf_woa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf62e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_rf_woa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys, y_perm_test_pred_rf_woa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52630a29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_rf_woa,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.964)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_rf_woa,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.875)')  \n",
    "\n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'  \n",
    "           , prop = font\n",
    "           , markerscale = 2\n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-RF-WOA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f948eef",
   "metadata": {},
   "source": [
    "# 5 XGBOOST-PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df645e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xgb_reg_PSO = xgb.XGBRegressor(random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4001a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    \n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_child_weight = int(solution[3])\n",
    "    subsample= solution[4]\n",
    "    colsample_bytree = solution[5]\n",
    "    \n",
    "    xgb_reg_PSO = XGBRegressor(random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1,colsample_bytree=colsample_bytree,learning_rate=learning_rate,max_depth=max_depth,n_estimators=n_estimators,min_child_weight=min_child_weight,subsample=subsample)\n",
    "    # Fit the model\n",
    "    xgb_reg_PSO.fit(X_RFE_train_xg, y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_xgb = xgb_reg_PSO.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_xgb = xgb_reg_PSO.predict(X_RFE_test_xg)\n",
    "    # Measure the performance\n",
    "    xgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_rmse_train = np.sqrt(xgb_mse_train)\n",
    "    xgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb)\n",
    "    xgb_rmse_test = np.sqrt(xgb_mse_test)\n",
    "    xgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_xgb)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 500,  1, 1,0.5,0.5],\n",
    "    \"ub\": [0.3 ,1500, 11, 20,1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"XG_PSO.log\"\n",
    "}\n",
    "model_XGB_PSO = PSO.BasePSO(problem, epoch=100, pop_size=50, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9)\n",
    "model_XGB_PSO.solve()\n",
    "best_position, best_fitness = model_XGB_PSO.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_XGB_PSO.history.list_global_best_fit, title='Global Best Fitness', filename='XGB_PSO_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_XGB_PSO.history.list_current_best_fit, title='Local Best Fitness', filename='XGB_PSO_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_XGB_PSO.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='XGB_PSO_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_XGB_PSO.history.list_exploration, model_XGB_PSO.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_XGB_PSO.history.list_diversity], list_legends=['XGB_PSO'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_XGB_PSO.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='XGB_PSO_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_XGB_PSO.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='XGB_PSO_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a3ac9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb_reg_PSO = XGBRegressor(random_state=42,learning_rate =0.01,n_estimators =692,max_depth=11,min_child_weight=4,subsample=0.6,colsample_bytree=0.9)\n",
    "xgb_reg_PSO.fit(X_RFE_train_xg, y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2215a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_pso = xgb_reg_PSO.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_xgb_pso = xgb_reg_PSO.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ed315",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_pso = y_perm_train_pred_xgb_pso.reshape(-1,1)\n",
    "y_perm_test_pred_xgb_pso = y_perm_test_pred_xgb_pso.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a9ad2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb_pso_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb_pso)\n",
    "xgb_pso_rmse_train = np.sqrt(xgb_pso_mse_train)\n",
    "xgb_pso_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb_pso)\n",
    "xgb_pso_rmse_test = np.sqrt(xgb_pso_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xgb_pso_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xgb_pso_rmse_test))\n",
    "xgb_pso_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb_pso)\n",
    "print('*  Train Score: %.4f MAE' % (xgb_pso_mae_train))\n",
    "xgb_pso_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb_pso)\n",
    "print('*  Test Score: %.4f MAE' % (xgb_pso_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_xgb_pso))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_xgb_pso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d21f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_xgb_pso,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.986)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_xgb_pso,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.876)')  \n",
    "\n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   \n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "plt.savefig('R2-XGB-PSO.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db259e",
   "metadata": {},
   "source": [
    "# XGBOOST-GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xgb_reg_GA = xgb.XGBRegressor(random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3eb85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    \n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_child_weight = int(solution[3])\n",
    "    subsample= solution[4]\n",
    "    colsample_bytree = solution[5]\n",
    "    \n",
    "    xgb_reg_GA = XGBRegressor(colsample_bytree=colsample_bytree,learning_rate=learning_rate,max_depth=max_depth,n_estimators=n_estimators,min_child_weight=min_child_weight,subsample=subsample,random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1)\n",
    "    # Fit the model\n",
    "    xgb_reg_GA.fit(X_RFE_train_xg, y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_xgb = xgb_reg_GA.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_xgb = xgb_reg_GA.predict(X_RFE_test_xg)\n",
    "    # Measure the performance\n",
    "    xgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_rmse_train = np.sqrt(xgb_mse_train)\n",
    "    xgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb)\n",
    "    xgb_rmse_test = np.sqrt(xgb_mse_test)\n",
    "    xgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_xgb)\n",
    "    return r2\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 500,  1, 1,0.5,0.5],\n",
    "    \"ub\": [0.3 ,1500, 11, 20,1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"XG_GA.log\"\n",
    "}\n",
    "model_XGB_GA = GA.BaseGA(problem, epoch=100, pop_size=50, pc=0.95, pm=0.1, mutation_multipoints=True, mutation=\"flip\")\n",
    "model_XGB_GA.solve()\n",
    "best_position, best_fitness = model_XGB_GA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_XGB_GA.history.list_global_best_fit, title='Global Best Fitness', filename='XGB_GA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_XGB_GA.history.list_current_best_fit, title='Local Best Fitness', filename='XGB_GA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_XGB_GA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='XGB_GA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_XGB_GA.history.list_exploration, model_XGB_GA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_XGB_GA.history.list_diversity], list_legends=['XGB_GA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_XGB_GA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='XGB_GA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_XGB_GA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='XGB_GA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg_GA = XGBRegressor(random_state=42,learning_rate =0.02,n_estimators =660,max_depth=7,min_child_weight=5,subsample=0.7,colsample_bytree=0.7)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "xgb_reg_GA.fit(X_RFE_train_xg, y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_ga = xgb_reg_GA.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_xgb_ga = xgb_reg_GA.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_ga = y_perm_train_pred_xgb_ga.reshape(-1,1)\n",
    "y_perm_test_pred_xgb_ga = y_perm_test_pred_xgb_ga.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8187c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ga_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb_ga)\n",
    "xgb_ga_rmse_train = np.sqrt(xgb_ga_mse_train)\n",
    "xgb_ga_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb_ga)\n",
    "xgb_ga_rmse_test = np.sqrt(xgb_ga_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xgb_ga_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xgb_ga_rmse_test))\n",
    "xgb_ga_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb_ga)\n",
    "print('*  Train Score: %.4f MAE' % (xgb_ga_mae_train))\n",
    "xgb_ga_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb_ga)\n",
    "print('*  Test Score: %.4f MAE' % (xgb_ga_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fce91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_xgb_ga))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_xgb_ga))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_xgb_ga,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.981)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_xgb_ga,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.876)') \n",
    "#plt.grid()  \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'  \n",
    "           , prop = font\n",
    "           , markerscale = 2\n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "plt.savefig('R2-XGB-GA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f23a8e",
   "metadata": {},
   "source": [
    "# XGBOOST-SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db37b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xgb_reg_SSA = xgb.XGBRegressor(random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d439eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    \n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_child_weight = int(solution[3])\n",
    "    subsample= solution[4]\n",
    "    colsample_bytree = solution[5]\n",
    "    \n",
    "    xgb_reg_SSA = XGBRegressor(colsample_bytree=colsample_bytree,learning_rate=learning_rate,max_depth=max_depth,n_estimators=n_estimators,min_child_weight=min_child_weight,subsample=subsample,random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1)\n",
    "    # Fit the model\n",
    "    xgb_reg_SSA.fit(X_RFE_train_xg, y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_xgb = xgb_reg_SSA.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_xgb = xgb_reg_SSA.predict(X_RFE_test_xg)\n",
    "  \n",
    "    xgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_rmse_train = np.sqrt(xgb_mse_train)\n",
    "    xgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb)\n",
    "    xgb_rmse_test = np.sqrt(xgb_mse_test)\n",
    "    xgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_xgb)\n",
    "    return r2\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 500,  1, 1,0.5,0.5],\n",
    "    \"ub\": [0.3 ,1500, 11, 20,1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"XG_SSA.log\"\n",
    "}\n",
    "model_XGB_SSA = SSA.BaseSSA(problem, epoch=100, pop_size=50, ST=0.8, PD=0.2, SD=0.1)\n",
    "model_XGB_SSA.solve()\n",
    "best_position, best_fitness = model_XGB_SSA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_XGB_SSA.history.list_global_best_fit, title='Global Best Fitness', filename='XGB_SSA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_XGB_SSA.history.list_current_best_fit, title='Local Best Fitness', filename='XGB_SSA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_XGB_SSA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='XGB_SSA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_XGB_SSA.history.list_exploration, model_XGB_SSA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_XGB_SSA.history.list_diversity], list_legends=['XGB_SSA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_XGB_SSA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='XGB_SSA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_XGB_SSA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='XGB_SSA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061abaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg_SSA = XGBRegressor(random_state=42,learning_rate =0.01,n_estimators =658,max_depth=9,min_child_weight=1,subsample=0.7,colsample_bytree=0.6)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "xgb_reg_SSA.fit(X_RFE_train_xg, y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d411a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_ssa = xgb_reg_SSA.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_xgb_ssa = xgb_reg_SSA.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_ssa = y_perm_train_pred_xgb_ssa.reshape(-1,1)\n",
    "y_perm_test_pred_xgb_ssa = y_perm_test_pred_xgb_ssa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_ssa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb_ssa)\n",
    "xgb_ssa_rmse_train = np.sqrt(xgb_ssa_mse_train)\n",
    "xgb_ssa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb_ssa)\n",
    "xgb_ssa_rmse_test = np.sqrt(xgb_ssa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xgb_ssa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xgb_ssa_rmse_test))\n",
    "\n",
    "xgb_ssa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb_ssa)\n",
    "print('*  Train Score: %.4f MAE' % (xgb_ssa_mae_train))\n",
    "xgb_ssa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb_ssa)\n",
    "print('*  Test Score: %.4f MAE' % (xgb_ssa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f072c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_xgb_ssa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_xgb_ssa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_xgb_ssa,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.989)') \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_xgb_ssa,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.876)')  \n",
    "#plt.grid()  \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   \n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-XGB-SSA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea8bc5",
   "metadata": {},
   "source": [
    "# XGBOOST -WOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "xgb_reg_WOA = xgb.XGBRegressor(random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    \n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    min_child_weight = int(solution[3])\n",
    "    subsample= solution[4]\n",
    "    colsample_bytree = solution[5]\n",
    "    \n",
    "    xgb_reg_WOA = XGBRegressor(colsample_bytree=colsample_bytree,learning_rate=learning_rate,max_depth=max_depth,n_estimators=n_estimators,min_child_weight=min_child_weight,subsample=subsample,random_state=42,tree_method='gpu_hist', gpu_id=0, n_jobs =-1)\n",
    "    # Fit the model\n",
    "    xgb_reg_WOA.fit(X_RFE_train_xg, y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_xgb = xgb_reg_WOA.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_xgb = xgb_reg_WOA.predict(X_RFE_test_xg)\n",
    "    # Measure the performance\n",
    "\n",
    "    xgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_rmse_train = np.sqrt(xgb_mse_train)\n",
    "    xgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb)\n",
    "    xgb_rmse_test = np.sqrt(xgb_mse_test)\n",
    "    xgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb)\n",
    "    xgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_xgb)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 500,  1, 1,0.5,0.5],\n",
    "    \"ub\": [0.3 ,1500, 11, 20,1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"XG_WOA.log\"\n",
    "}\n",
    "model_XGB_WOA =WOA.HI_WOA(problem, epoch=100, pop_size=50, feedback_max=5)\n",
    "model_XGB_WOA.solve()\n",
    "best_position, best_fitness = model_XGB_WOA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_XGB_WOA.history.list_global_best_fit, title='Global Best Fitness', filename='XGB_WOA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_XGB_WOA.history.list_current_best_fit, title='Local Best Fitness', filename='XGB_WOA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_XGB_WOA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='XGB_WOA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_XGB_WOA.history.list_exploration, model_XGB_WOA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_XGB_WOA.history.list_diversity], list_legends=['XGB_WOA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_XGB_WOA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='XGB_WOA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_XGB_WOA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='XGB_WOA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550929c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg_WOA = XGBRegressor(random_state=42,learning_rate =0.02,n_estimators =597,max_depth=7,min_child_weight=15,subsample=0.7,colsample_bytree=0.5)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "xgb_reg_WOA.fit(X_RFE_train_xg, y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19631845",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_woa = xgb_reg_WOA.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_xgb_woa = xgb_reg_WOA.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7535f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_xgb_woa = y_perm_train_pred_xgb_woa.reshape(-1,1)\n",
    "y_perm_test_pred_xgb_woa = y_perm_test_pred_xgb_woa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_woa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_xgb_woa)\n",
    "xgb_woa_rmse_train = np.sqrt(xgb_woa_mse_train)\n",
    "xgb_woa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_xgb_woa)\n",
    "xgb_woa_rmse_test = np.sqrt(xgb_woa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (xgb_woa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (xgb_woa_rmse_test))\n",
    "\n",
    "xgb_woa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_xgb_woa)\n",
    "print('*  Train Score: %.4f MAE' % (xgb_woa_mae_train))\n",
    "xgb_woa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_xgb_woa)\n",
    "print('*  Test Score: %.4f MAE' % (xgb_woa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_xgb_woa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys, y_perm_test_pred_xgb_woa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f44130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_xgb_ga,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.955)')  #\n",
    "plt.scatter(y_test_ys,y_perm_test_pred_xgb_ga,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.872)')  \n",
    "#plt.grid()  \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'  \n",
    "           , prop = font\n",
    "           , markerscale = 2\n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-XGB-WOA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9077e",
   "metadata": {},
   "source": [
    "# 6 lightGBM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c7212",
   "metadata": {},
   "source": [
    "# LightGBM -PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac082aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lgb_reg_PSO = lgb.LGBMRegressor(random_state=42,device = 'gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42692728",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    learning_rate_lgb = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth_lgb = int(solution[2])\n",
    "    feature_fraction_lgb = solution[3]\n",
    "    bagging_fraction_lgb = solution[4]\n",
    "    \n",
    "    lgb_reg_PSO = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=learning_rate_lgb,max_depth=max_depth_lgb,feature_fraction=feature_fraction_lgb,bagging_fraction=bagging_fraction_lgb,n_estimators =n_estimators)\n",
    "    # Fit the model\n",
    "    lgb_reg_PSO.fit(X_boruta_train_lg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_lgb = lgb_reg_PSO.predict(X_boruta_train_lg)\n",
    "    y_perm_test_pred_lgb = lgb_reg_PSO.predict(X_boruta_test_lg)\n",
    "    # Measure the performance\n",
    "    #未进行反归一化\n",
    "    #calculate root mean squared error均方根误差\n",
    "    lgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_rmse_train = np.sqrt(lgb_mse_train)\n",
    "    lgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb)\n",
    "    lgb_rmse_test = np.sqrt(lgb_mse_test)\n",
    "    lgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb)\n",
    "    r2 = r2_score(y_test_ys, y_perm_test_pred_lgb)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 100,  1, 0.5,0.5],\n",
    "    \"ub\": [0.3 , 3000,11, 1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"LG_PSO.log\"\n",
    "}\n",
    "model_LGB_PSO = PSO.BasePSO(problem, epoch=100, pop_size=50, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9)\n",
    "model_LGB_PSO.solve()\n",
    "best_position, best_fitness = model_LGB_PSO.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f20703",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_LGB_PSO.history.list_global_best_fit, title='Global Best Fitness', filename='LGB_PSO_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_LGB_PSO.history.list_current_best_fit, title='Local Best Fitness', filename='LGB_PSO_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_LGB_PSO.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='LGB_PSO_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_LGB_PSO.history.list_exploration, model_LGB_PSO.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_LGB_PSO.history.list_diversity], list_legends=['LGB_PSO'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_LGB_PSO.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='LGB_PSO_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_LGB_PSO.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='LGB_PSO_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda08ba6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgb_reg_PSO = LGBMRegressor(random_state=42,learning_rate=0.13,n_estimators =100,max_depth=11,feature_fraction =1,bagging_fraction=0.5)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "lgb_reg_PSO.fit(X_boruta_train_lg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd69184",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_pso = lgb_reg_PSO.predict(X_boruta_train_lg)\n",
    "y_perm_test_pred_lgb_pso = lgb_reg_PSO.predict(X_boruta_test_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929511b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_pso = y_perm_train_pred_lgb_pso.reshape(-1,1)\n",
    "y_perm_test_pred_lgb_pso = y_perm_test_pred_lgb_pso.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018ca8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lgb_pso_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb_pso)\n",
    "lgb_pso_rmse_train = np.sqrt(lgb_pso_mse_train)\n",
    "lgb_pso_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb_pso)\n",
    "lgb_pso_rmse_test = np.sqrt(lgb_pso_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lgb_pso_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lgb_pso_rmse_test))\n",
    "\n",
    "lgb_pso_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb_pso)\n",
    "print('*  Train Score: %.4f MAE' % (lgb_pso_mae_train))\n",
    "lgb_pso_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb_pso)\n",
    "print('*  Test Score: %.4f MAE' % (lgb_pso_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd86fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_lgb_pso))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_lgb_pso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822d4a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_lgb_pso,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.961)')  #\n",
    "plt.scatter(y_test_ys,y_perm_test_pred_lgb_pso,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.862)')  #\n",
    "\n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   #\n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-LGB-PSO.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e0891",
   "metadata": {},
   "source": [
    "# LightGBM-GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7a59a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lgb_reg_GA = lgb.LGBMRegressor(random_state=42,device = 'gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18714c09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    learning_rate_lgb = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth_lgb = int(solution[2])\n",
    "    feature_fraction_lgb = solution[3]\n",
    "    bagging_fraction_lgb = solution[4]\n",
    "    \n",
    "    lgb_reg_GA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=learning_rate_lgb,max_depth=max_depth_lgb,feature_fraction=feature_fraction_lgb,bagging_fraction=bagging_fraction_lgb,n_estimators =n_estimators)\n",
    "    # Fit the model\n",
    "    lgb_reg_GA.fit(X_boruta_train_lg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_lgb = lgb_reg_GA.predict(X_boruta_train_lg)\n",
    "    y_perm_test_pred_lgb = lgb_reg_GA.predict(X_boruta_test_lg)\n",
    "    # Measure the performance\n",
    "    #未进行反归一化\n",
    "    #calculate root mean squared error均方根误差\n",
    "    lgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_rmse_train = np.sqrt(lgb_mse_train)\n",
    "    lgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb)\n",
    "    lgb_rmse_test = np.sqrt(lgb_mse_test)\n",
    "    lgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb)\n",
    "    r2 = r2_score(y_test_ys, y_perm_test_pred_lgb)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 100,  1, 0.5,0.5],\n",
    "    \"ub\": [0.3 , 3000,11, 1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"LG_GA.log\"\n",
    "}\n",
    "model_LGB_GA = GA.BaseGA(problem, epoch=100, pop_size=50, pc=0.95, pm=0.1, mutation_multipoints=True, mutation=\"flip\")\n",
    "model_LGB_GA.solve()\n",
    "best_position, best_fitness = model_LGB_GA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81061e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_LGB_GA.history.list_global_best_fit, title='Global Best Fitness', filename='LGB_GA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_LGB_GA.history.list_current_best_fit, title='Local Best Fitness', filename='LGB_GA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_LGB_GA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='LGB_GA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_LGB_GA.history.list_exploration, model_LGB_GA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_LGB_GA.history.list_diversity], list_legends=['LGB_GA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_LGB_GA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='LGB_GA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_LGB_GA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='LGB_GA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2b049",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgb_reg_GA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=0.09,n_estimators =131,max_depth=10,feature_fraction =0.7,bagging_fraction=0.8)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "lgb_reg_GA.fit(X_boruta_train_lg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd77095",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_ga = lgb_reg_GA.predict(X_boruta_train_lg)\n",
    "y_perm_test_pred_lgb_ga = lgb_reg_GA.predict(X_boruta_test_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161acccb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_ga = y_perm_train_pred_lgb_ga.reshape(-1,1)\n",
    "y_perm_test_pred_lgb_ga = y_perm_test_pred_lgb_ga.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f30c18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lgb_ga_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb_ga)\n",
    "lgb_ga_rmse_train = np.sqrt(lgb_ga_mse_train)\n",
    "lgb_ga_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb_ga)\n",
    "lgb_ga_rmse_test = np.sqrt(lgb_ga_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lgb_ga_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lgb_ga_rmse_test))\n",
    "\n",
    "lgb_ga_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb_ga)\n",
    "print('*  Train Score: %.4f MAE' % (lgb_ga_mae_train))\n",
    "lgb_ga_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb_ga)\n",
    "print('*  Test Score: %.4f MAE' % (lgb_ga_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64265f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_lgb_ga))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_lgb_ga))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef671cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_lgb_pso,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.951)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_lgb_pso,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.870)')  \n",
    "#plt.grid()  # \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   \n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-LGB-GA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e43054f",
   "metadata": {},
   "source": [
    "# LightGBM-SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a3a2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lgb_reg_SSA = lgb.LGBMRegressor(random_state=42,device = 'gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1c1f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    learning_rate_lgb = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth_lgb = int(solution[2])\n",
    "    feature_fraction_lgb = solution[3]\n",
    "    bagging_fraction_lgb = solution[4]\n",
    "    \n",
    "    lgb_reg_SSA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=learning_rate_lgb,max_depth=max_depth_lgb,feature_fraction=feature_fraction_lgb,bagging_fraction=bagging_fraction_lgb,n_estimators =n_estimators)\n",
    "    # Fit the model\n",
    "    lgb_reg_SSA.fit(X_boruta_train_lg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_lgb = lgb_reg_SSA.predict(X_boruta_train_lg)\n",
    "    y_perm_test_pred_lgb = lgb_reg_SSA.predict(X_boruta_test_lg)\n",
    "    # Measure the performance\n",
    "    lgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_rmse_train = np.sqrt(lgb_mse_train)\n",
    "    lgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb)\n",
    "    lgb_rmse_test = np.sqrt(lgb_mse_test)\n",
    "    lgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb)\n",
    "    r2 = r2_score(y_test_ys, y_perm_test_pred_lgb)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 100,  1, 0.5,0.5],\n",
    "    \"ub\": [0.3 , 3000,11, 1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"XG_SSA.log\"\n",
    "}\n",
    "model_LGB_SSA = SSA.BaseSSA(problem, epoch=100, pop_size=50, ST=0.8, PD=0.2, SD=0.1)\n",
    "model_LGB_SSA.solve()\n",
    "best_position, best_fitness = model_LGB_SSA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_LGB_SSA.history.list_global_best_fit, title='Global Best Fitness', filename='LGB_SSA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_LGB_SSA.history.list_current_best_fit, title='Local Best Fitness', filename='LGB_SSA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_LGB_SSA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='LGB_SSA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_LGB_SSA.history.list_exploration, model_LGB_SSA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_LGB_SSA.history.list_diversity], list_legends=['LGB_SSA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_LGB_SSA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='LGB_SSA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_LGB_SSA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='LGB_SSA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8aaf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgb_reg_SSA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=0.03,n_estimators =368,max_depth=11,feature_fraction =1,bagging_fraction=0.8)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "lgb_reg_SSA.fit(X_boruta_train_lg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15139a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_ssa = lgb_reg_SSA.predict(X_boruta_train_lg)\n",
    "y_perm_test_pred_lgb_ssa = lgb_reg_SSA.predict(X_boruta_test_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fceff31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_ssa = y_perm_train_pred_lgb_ssa.reshape(-1,1)\n",
    "y_perm_test_pred_lgb_ssa = y_perm_test_pred_lgb_ssa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebd2da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lgb_ssa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb_ssa)\n",
    "lgb_ssa_rmse_train = np.sqrt(lgb_ssa_mse_train)\n",
    "lgb_ssa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb_ssa)\n",
    "lgb_ssa_rmse_test = np.sqrt(lgb_ssa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lgb_ssa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lgb_ssa_rmse_test))\n",
    "\n",
    "lgb_ssa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb_ssa)\n",
    "print('*  Train Score: %.4f MAE' % (lgb_ssa_mae_train))\n",
    "lgb_ssa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb_ssa)\n",
    "print('*  Test Score: %.4f MAE' % (lgb_ssa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675916f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_lgb_ssa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_lgb_ssa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2e2ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_lgb_ssa,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.954)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_lgb_ssa,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.869)')  \n",
    "#plt.grid()  # \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   #\n",
    "           , prop = font\n",
    "           , markerscale = 2#\n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-LGB-SSA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5c4f1",
   "metadata": {},
   "source": [
    "# LightGBM -WOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50578a5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "lgb_reg_WOA = lgb.LGBMRegressor(random_state=42,device = 'gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8ab84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid   \n",
    "    learning_rate_lgb = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    max_depth_lgb = int(solution[2])\n",
    "    feature_fraction_lgb = solution[3]\n",
    "    bagging_fraction_lgb = solution[4]\n",
    "    \n",
    "    lgb_reg_WOA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=learning_rate_lgb,max_depth=max_depth_lgb,feature_fraction=feature_fraction_lgb,bagging_fraction=bagging_fraction_lgb,n_estimators =n_estimators)\n",
    "    # Fit the model\n",
    "    lgb_reg_WOA.fit(X_boruta_train_lg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_lgb = lgb_reg_WOA.predict(X_boruta_train_lg)\n",
    "    y_perm_test_pred_lgb = lgb_reg_WOA.predict(X_boruta_test_lg)\n",
    "    # Measure the performance\n",
    "\n",
    "    lgb_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_rmse_train = np.sqrt(lgb_mse_train)\n",
    "    lgb_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb)\n",
    "    lgb_rmse_test = np.sqrt(lgb_mse_test)\n",
    "    lgb_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb)\n",
    "    lgb_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb)\n",
    "    r2 = r2_score(y_test_ys, y_perm_test_pred_lgb)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01, 100,  1, 0.5,0.5],\n",
    "    \"ub\": [0.3 , 3000,11, 1,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"LG_WOA.log\"\n",
    "}\n",
    "model_LGB_WOA = WOA.HI_WOA(problem, epoch=100, pop_size=50, feedback_max=5)\n",
    "model_LGB_WOA.solve()\n",
    "best_position, best_fitness = model_LGB_WOA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10aca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_LGB_WOA.history.list_global_best_fit, title='Global Best Fitness', filename='LGB_WOA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_LGB_WOA.history.list_current_best_fit, title='Local Best Fitness', filename='LGB_WOA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_LGB_WOA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='LGB_WOA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_LGB_WOA.history.list_exploration, model_LGB_WOA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_LGB_WOA.history.list_diversity], list_legends=['LGB_WOA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_LGB_WOA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='LGB_WOA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_LGB_WOA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='LGB_WOA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_WOA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=0.17,n_estimators =100,max_depth=6,feature_fraction =0.7,bagging_fraction=0.9)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "lgb_reg_WOA.fit(X_boruta_train_lg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd2aff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_woa = lgb_reg_WOA.predict(X_boruta_train_lg)\n",
    "y_perm_test_pred_lgb_woa = lgb_reg_WOA.predict(X_boruta_test_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16146c87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_perm_train_pred_lgb_woa = y_perm_train_pred_lgb_woa.reshape(-1,1)\n",
    "y_perm_test_pred_lgb_woa = y_perm_test_pred_lgb_woa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5be48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lgb_woa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_lgb_woa)\n",
    "lgb_woa_rmse_train = np.sqrt(lgb_woa_mse_train)\n",
    "lgb_woa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_lgb_woa)\n",
    "lgb_woa_rmse_test = np.sqrt(lgb_woa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (lgb_woa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (lgb_woa_rmse_test))\n",
    "\n",
    "lgb_woa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_lgb_woa)\n",
    "print('*  Train Score: %.4f MAE' % (lgb_woa_mae_train))\n",
    "lgb_woa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_lgb_woa)\n",
    "print('*  Test Score: %.4f MAE' % (lgb_woa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_lgb_woa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys, y_perm_test_pred_lgb_woa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd03eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_lgb_woa,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.948)')  #\n",
    "plt.scatter(y_test_ys,y_perm_test_pred_lgb_woa,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.867)')  \n",
    "#plt.grid()  # \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "#\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   # \n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "#保存图片\n",
    "plt.savefig('R2-LGB-WOA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  # 显示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae33bb",
   "metadata": {},
   "source": [
    "# # NGBoost: Natural Gradient Boosting for Probabilistic Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60fd065",
   "metadata": {},
   "source": [
    "#  NGBOOST- PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4cbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_PSO = NGBRegressor(random_state=42,natural_gradient=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e913480",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    minibatch_frac = solution[2]\n",
    "    ng_reg_PSO = NGBRegressor(learning_rate=learning_rate,n_estimators=n_estimators,minibatch_frac=minibatch_frac )\n",
    "    # Fit the model\n",
    "    ng_reg_PSO.fit(X_RFE_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_ng = ng_reg_PSO.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_ng = ng_reg_PSO.predict(X_RFE_test_xg)\n",
    "    # Measure the performance\n",
    "\n",
    "    ng_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_rmse_train = np.sqrt(ng_mse_train)\n",
    "    ng_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng)\n",
    "    ng_rmse_test = np.sqrt(ng_mse_test)\n",
    "    ng_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_ng)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01,100,0.5],\n",
    "    \"ub\": [0.1,1500,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"NG_PSO.log\"\n",
    "}\n",
    "model_NGB_PSO = PSO.BasePSO(problem, epoch=100, pop_size=50, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9)\n",
    "model_NGB_PSO.solve()\n",
    "best_position, best_fitness = model_NGB_PSO.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_NGB_PSO.history.list_global_best_fit, title='Global Best Fitness', filename='NGB_PSO_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_NGB_PSO.history.list_current_best_fit, title='Local Best Fitness', filename='NGB_PSO_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_NGB_PSO.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='NGB_PSO_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_NGB_PSO.history.list_exploration, model_NGB_PSO.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_NGB_PSO.history.list_diversity], list_legends=['NGB_PSO'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_NGB_PSO.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='NGB_PSO_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_NGB_PSO.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='NGB_PSO_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_PSO = NGBRegressor(learning_rate=0.08,n_estimators=1500,minibatch_frac=0.8,random_state=42,natural_gradient=True)\n",
    "# Fit the model\n",
    "ng_reg_PSO.fit(X_RFE_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026797cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_pso = ng_reg_PSO.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_ng_pso = ng_reg_PSO.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_pso = y_perm_train_pred_ng_pso.reshape(-1,1)\n",
    "y_perm_test_pred_ng_pso = y_perm_test_pred_ng_pso.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77082ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "ng_pso_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng_pso)\n",
    "ng_pso_rmse_train = np.sqrt(ng_pso_mse_train)\n",
    "ng_pso_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng_pso)\n",
    "ng_pso_rmse_test = np.sqrt(ng_pso_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ng_pso_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ng_pso_rmse_test))\n",
    "\n",
    "ng_pso_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng_pso)\n",
    "print('*  Train Score: %.4f MAE' % (ng_pso_mae_train))\n",
    "ng_pso_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng_pso)\n",
    "print('*  Test Score: %.4f MAE' % (ng_pso_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8dc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_ng_pso))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_ng_pso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86065856",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_ng_pso,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.989)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_ng_pso,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.859)')  \n",
    "#plt.grid()  \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "#\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   #\n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-NGB-PSO.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16c3cb",
   "metadata": {},
   "source": [
    "#  NGBOOST-GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79895254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_GA = NGBRegressor(random_state=42,natural_gradient=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODER\n",
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    minibatch_frac = solution[2]\n",
    "    ng_reg_GA = NGBRegressor(learning_rate=learning_rate,n_estimators=n_estimators,minibatch_frac=minibatch_frac,random_state=42,natural_gradient=True )\n",
    "    # Fit the model\n",
    "    ng_reg_GA.fit(X_RFE_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_ng = ng_reg_GA.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_ng = ng_reg_GA.predict(X_RFE_test_xg)\n",
    "    # Measure the performance\n",
    "\n",
    "    ng_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_rmse_train = np.sqrt(ng_mse_train)\n",
    "    ng_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng)\n",
    "    ng_rmse_test = np.sqrt(ng_mse_test)\n",
    "    ng_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_ng)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01,100,0.5],\n",
    "    \"ub\": [0.1,1500,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"NG_GA.log\"\n",
    "}\n",
    "model_NGB_GA = GA.BaseGA(problem, epoch=100, pop_size=50, pc=0.95, pm=0.1, mutation_multipoints=True, mutation=\"flip\")\n",
    "model_NGB_GA.solve()\n",
    "best_position, best_fitness = model_NGB_GA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ecf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_NGB_GA.history.list_global_best_fit, title='Global Best Fitness', filename='NGB_GA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_NGB_GA.history.list_current_best_fit, title='Local Best Fitness', filename='NGB_GA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_NGB_GA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='NGB_GA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_NGB_GA.history.list_exploration, model_NGB_GA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_NGB_GA.history.list_diversity], list_legends=['NGB_GA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_NGB_GA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='NGB_GA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_NGB_GA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='NGB_GA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_GA = NGBRegressor(learning_rate=0.03,n_estimators=1473,minibatch_frac=0.7,random_state=42,natural_gradient=True)\n",
    "# Fit the model\n",
    "ng_reg_GA.fit(X_RFE_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_ga = ng_reg_GA.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_ng_ga = ng_reg_GA.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_ga = y_perm_train_pred_ng_ga.reshape(-1,1)\n",
    "y_perm_test_pred_ng_ga = y_perm_test_pred_ng_ga.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ng_ga_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng_ga)\n",
    "ng_ga_rmse_train = np.sqrt(ng_ga_mse_train)\n",
    "ng_ga_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng_ga)\n",
    "ng_ga_rmse_test = np.sqrt(ng_ga_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ng_ga_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ng_ga_rmse_test))\n",
    "\n",
    "ng_ga_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng_ga)\n",
    "print('*  Train Score: %.4f MAE' % (ng_ga_mae_train))\n",
    "ng_ga_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng_ga)\n",
    "print('*  Test Score: %.4f MAE' % (ng_ga_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fe754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_ng_ga))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_ng_ga))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_ng_ga,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.963)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_ng_ga,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.866)')  #\n",
    "#plt.grid()  # \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   #\n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "#保存图片\n",
    "plt.savefig('R2-NGB-GA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  # 显示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33a9e9",
   "metadata": {},
   "source": [
    "# NGBOOST-SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_SSA = NGBRegressor(random_state=42,natural_gradient=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODER\n",
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    minibatch_frac = solution[2]\n",
    "    ng_reg_SSA = NGBRegressor(learning_rate=learning_rate,n_estimators=n_estimators,minibatch_frac=minibatch_frac )\n",
    "    ng_reg_SSA.fit(X_RFE_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_ng = ng_reg_SSA.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_ng = ng_reg_SSA.predict(X_RFE_test_xg)\n",
    "    # Measure the performance\n",
    "    ng_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_rmse_train = np.sqrt(ng_mse_train)\n",
    "    ng_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng)\n",
    "    ng_rmse_test = np.sqrt(ng_mse_test)\n",
    "    ng_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_ng)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01,100,0.5],\n",
    "    \"ub\": [0.1,1500,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"NG_SSA.log\"\n",
    "}\n",
    "model_NGB_SSA =SSA.BaseSSA(problem, epoch=100, pop_size=50, ST=0.8, PD=0.2, SD=0.1)\n",
    "\n",
    "model_NGB_SSA.solve()\n",
    "best_position, best_fitness = model_NGB_SSA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_NGB_SSA.history.list_global_best_fit, title='Global Best Fitness', filename='NGB_SSA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_NGB_SSA.history.list_current_best_fit, title='Local Best Fitness', filename='NGB_SSA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_NGB_SSA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='NGB_SSA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_NGB_SSA.history.list_exploration, model_NGB_SSA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_NGB_SSA.history.list_diversity], list_legends=['NGB_SSA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_NGB_SSA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='NGB_SSA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_NGB_SSA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='NGB_SSA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_SSA = NGBRegressor(learning_rate=0.08,n_estimators=1500,minibatch_frac=0.8,random_state=42,natural_gradient=True)\n",
    "# Fit the model\n",
    "ng_reg_SSA.fit(X_RFE_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076403aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_ssa = ng_reg_SSA.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_ng_ssa = ng_reg_SSA.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8413310",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_ssa = y_perm_train_pred_ng_ssa.reshape(-1,1)\n",
    "y_perm_test_pred_ng_ssa = y_perm_test_pred_ng_ssa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259da1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ng_ssa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng_ssa)\n",
    "ng_ssa_rmse_train = np.sqrt(ng_ssa_mse_train)\n",
    "ng_ssa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng_ssa)\n",
    "ng_ssa_rmse_test = np.sqrt(ng_ssa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ng_ssa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ng_ssa_rmse_test))\n",
    "\n",
    "ng_ssa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng_ssa)\n",
    "print('*  Train Score: %.4f MAE' % (ng_ssa_mae_train))\n",
    "ng_ssa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng_ssa)\n",
    "print('*  Test Score: %.4f MAE' % (ng_ssa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cf7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_ng_ssa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_ng_ssa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_ng_ssa,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.989)')  \n",
    "plt.scatter(y_test_ys,y_perm_test_pred_ng_ssa,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.860)')  # \n",
    "#plt.grid()  # \n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   \n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "#保存图片\n",
    "plt.savefig('R2-NGB-SSA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a6db8",
   "metadata": {},
   "source": [
    "# NGBOOST-WOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_WOA = NGBRegressor(random_state=42,natural_gradient=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34151fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODER\n",
    "# print(KERNEL_ENCODER.inverse_transform( [1, 3]))\n",
    "starttime = datetime.datetime.now()\n",
    "def fitness_function(solution):\n",
    "    # if kernel belongs to 0 - 0.99 ==> 0       ==> linear\n",
    "    #                       2 - 2.99 ==> 2\n",
    "    #                       3 - 3.99 ==> 3      ==> sigmoid\n",
    "    learning_rate = solution[0]\n",
    "    n_estimators = int(solution[1])\n",
    "    minibatch_frac = solution[2]\n",
    "    ng_reg_WOA = NGBRegressor(learning_rate=learning_rate,n_estimators=n_estimators,minibatch_frac=minibatch_frac,random_state=42,natural_gradient=True )\n",
    "    # Fit the model\n",
    "    ng_reg_WOA.fit(X_RFE_train_xg,y_train_ys)\n",
    "    # Make the predictions\n",
    "    y_perm_train_pred_ng = ng_reg_WOA.predict(X_RFE_train_xg)\n",
    "    y_perm_test_pred_ng = ng_reg_WOA.predict(X_RFE_test_xg)\n",
    "    # Measure the performance\n",
    "    ng_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_rmse_train = np.sqrt(ng_mse_train)\n",
    "    ng_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng)\n",
    "    ng_rmse_test = np.sqrt(ng_mse_test)\n",
    "    ng_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng)\n",
    "    ng_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng)\n",
    "    r2 = r2_score(y_test_ys,y_perm_test_pred_ng)\n",
    "    return r2\n",
    "\n",
    "problem = {\n",
    "    \n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [0.01,100,0.5],\n",
    "    \"ub\": [0.1,1500,1],\n",
    "    \"minmax\": \"max\",\n",
    "    \"log_to\": \"file\",\n",
    "    \"log_file\": \"NG_WOA.log\"\n",
    "}\n",
    "model_NGB_WOA = WOA.HI_WOA(problem, epoch=100, pop_size=50, feedback_max=5)\n",
    "model_NGB_WOA.solve()\n",
    "best_position, best_fitness = model_NGB_WOA.solve()\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5520185",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_convergence_chart(model_NGB_WOA.history.list_global_best_fit, title='Global Best Fitness', filename='NGB_WOA_Global Best Fitness')            # Draw global best fitness found so far in previous generations\n",
    "export_convergence_chart(model_NGB_WOA.history.list_current_best_fit, title='Local Best Fitness', filename='NGB_WOA_Local Best Fitness')             # Draw current best fitness in each previous generation\n",
    "export_convergence_chart(model_NGB_WOA.history.list_epoch_time, title='Runtime chart', y_label=\"Second\", filename='NGB_WOA_Runtime chart')        # Draw runtime for each generation\n",
    "## On the exploration and exploitation in popular swarm-based metaheuristic algorithms\n",
    "\n",
    "# This exploration/exploitation chart should draws for single algorithm and single fitness function\n",
    "export_explore_exploit_chart([model_NGB_WOA.history.list_exploration, model_NGB_WOA.history.list_exploitation])  # Draw exploration and exploitation chart\n",
    "\n",
    "# This diversity chart should draws for multiple algorithms for a single fitness function at the same time to compare the diversity spreading\n",
    "export_diversity_chart([model_NGB_WOA.history.list_diversity], list_legends=['NGB_WOA'])        # Draw diversity measurement chart\n",
    "\n",
    "## Because convergence chart is formulated from objective values and weights, thus we also want to draw objective charts to understand the convergence\n",
    "# Need a little bit more pre-processing\n",
    "global_obj_list = np.array([agent[1][1] for agent in model_NGB_WOA.history.list_global_best])     # 2D array / matrix 2D\n",
    "global_obj_list = [global_obj_list[:,idx] for idx in range(0, len(global_obj_list[0]))]     # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(global_obj_list, title='Global Objectives Chart', filename='NGB_WOA_Global Objectives Chart')\n",
    "current_obj_list = np.array([agent[1][1] for agent in model_NGB_WOA.history.list_current_best])  # 2D array / matrix 2D\n",
    "current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]  # Make each obj_list as a element in array for drawing\n",
    "export_objectives_chart(current_obj_list, title='Local Objectives Chart', filename='NGB_WOA_Local Objectives Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_reg_WOA = NGBRegressor(learning_rate=0.0477398081,n_estimators=1486,minibatch_frac=0.688610492,random_state=42,natural_gradient=True)\n",
    "# Fit the model\n",
    "ng_reg_WOA.fit(X_RFE_train_xg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_woa = ng_reg_WOA.predict(X_RFE_train_xg)\n",
    "y_perm_test_pred_ng_woa = ng_reg_WOA.predict(X_RFE_test_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_train_pred_ng_woa = y_perm_train_pred_ng_woa.reshape(-1,1)\n",
    "y_perm_test_pred_ng_woa = y_perm_test_pred_ng_woa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e80660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ng_woa_mse_train = mean_squared_error(y_train_ys,y_perm_train_pred_ng_woa)\n",
    "ng_woa_rmse_train = np.sqrt(ng_woa_mse_train)\n",
    "ng_woa_mse_test = mean_squared_error(y_test_ys,y_perm_test_pred_ng_woa)\n",
    "ng_woa_rmse_test = np.sqrt(ng_woa_mse_test)\n",
    "print('*  Train Score: %.4f RMSE' % (ng_woa_rmse_train))\n",
    "print('*  Test Score: %.4f RMSE' % (ng_woa_rmse_test))\n",
    "ng_woa_mae_train = mean_absolute_error(y_train_ys,y_perm_train_pred_ng_woa)\n",
    "print('*  Train Score: %.4f MAE' % (ng_woa_mae_train))\n",
    "ng_woa_mae_test = mean_absolute_error(y_test_ys, y_perm_test_pred_ng_woa)\n",
    "print('*  Test Score: %.4f MAE' % (ng_woa_mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b19051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train R2 score:\", r2_score(y_train_ys,y_perm_train_pred_ng_woa))\n",
    "print(\"Test R2 score:\", r2_score(y_test_ys,y_perm_test_pred_ng_woa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32028c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figsize = 4, 4\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(y_train_ys,y_perm_train_pred_ng_woa,s=30, c=\"r\",marker='o',label='Train(R\\u00b2=0.977)')  #\n",
    "plt.scatter(y_test_ys,y_perm_test_pred_ng_woa,s=30, c=\"b\",marker='o',label='Test(R\\u00b2=0.862)')  #\n",
    "#plt.grid()  #\n",
    "plt.xlim(-2, 3)\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=3,color='black',label=\"1:1 Line\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured Log K(mD)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.ylabel(\"Predicted Log K(mD)\", fontproperties=\"Times New Roman\",fontsize=20)\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'bold'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':8\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   \n",
    "           , prop = font\n",
    "           , markerscale = 2# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('R2-NGB-WOA.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042af1d",
   "metadata": {},
   "source": [
    "# Blind test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c890410",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_WOA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=0.17,n_estimators =100,max_depth=6,feature_fraction =0.7,bagging_fraction=0.9)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "lgb_reg_WOA.fit(X_boruta_train_lg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = pd.read_csv('BlindTestWellA.csv')\n",
    "val_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4789ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = val_set.values\n",
    "val_set = val_set.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_set\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c58358",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_pd=X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_val_predict_xgb = lgb_reg_WOA.predict(X_val_pd)\n",
    "print(y_perm_val_predict_xgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f94069",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_val_predict_xgb = y_perm_val_predict_xgb.reshape(-1,1)\n",
    "#inverse_xgb_perm_val = min_max_scaler_y_perm.inverse_transform(y_perm_val_predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_perm_val_predict_xgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_perm_val=pd.DataFrame(10**y_perm_val_predict_xgb)\n",
    "xgb_perm_val.to_csv('vali_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead83b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_blindtest = pd.read_csv('Validataion.csv')\n",
    "val_blindtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_blindtest = val_blindtest.values\n",
    "val_blindtest = val_blindtest.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_core = val_blindtest[:,0]\n",
    "perm_fit = val_blindtest[:,1]\n",
    "perm_predict = val_blindtest[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse_Core_Fit = mean_squared_error(perm_core,perm_fit)\n",
    "rmse_Core_Fit = np.sqrt(mse_Core_Fit)\n",
    "mse_Core_Predict = mean_squared_error(perm_core,perm_predict)\n",
    "rmse_Core_Predict = np.sqrt(mse_Core_Predict)\n",
    "print('*  Core_Fit: %.4f RMSE' % (rmse_Core_Fit))\n",
    "print('*  Core_Predict: %.4f RMSE' % (rmse_Core_Predict))\n",
    "\n",
    "mae_Core_Fit = mean_absolute_error(perm_core,perm_fit)\n",
    "print('*  Core_Fit: %.4f MAE' % (mae_Core_Fit))\n",
    "mae_Core_Predict = mean_absolute_error(perm_core,perm_predict)\n",
    "print('*  Core_Predict: %.4f MAE' % (mae_Core_Predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d44bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_Fitr2 = r2_score(perm_core,perm_fit)\n",
    "Core_Predictr2 = r2_score(perm_core,perm_predict)\n",
    "print(\"Core_Fitr2 score:\", r2_score(perm_core,perm_fit))\n",
    "print(\"Core_Predictr2 score:\", r2_score(perm_core,perm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_WOA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=0.17,n_estimators =100,max_depth=6,feature_fraction =0.7,bagging_fraction=0.9)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)\n",
    "# Fit the model\n",
    "lgb_reg_WOA.fit(X_boruta_train_lg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = pd.read_csv('BlindTestWellA.csv')\n",
    "val_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = val_set.values\n",
    "val_set = val_set.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_set\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_pd=X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_val_predict_xgb = lgb_reg_WOA.predict(X_val_pd)\n",
    "print(y_perm_val_predict_xgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perm_val_predict_xgb = y_perm_val_predict_xgb.reshape(-1,1)\n",
    "#inverse_xgb_perm_val = min_max_scaler_y_perm.inverse_transform(y_perm_val_predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_perm_val_predict_xgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b716d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_perm_val=pd.DataFrame(10**y_perm_val_predict_xgb)\n",
    "xgb_perm_val.to_csv('vali_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba77712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f7024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49376d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_blindtest = pd.read_csv('WELLAVALIDATION.csv')\n",
    "val_blindtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64399a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_blindtest = val_blindtest.values\n",
    "val_blindtest = val_blindtest.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1da259",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_core = val_blindtest[:,0]\n",
    "perm_fit = val_blindtest[:,1]\n",
    "fk_fit = val_blindtest[:,2]\n",
    "perm_predict = val_blindtest[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a0731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse_Core_Fit = mean_squared_error(perm_core,perm_fit)\n",
    "rmse_Core_Fit = np.sqrt(mse_Core_Fit)\n",
    "mse_Core_FK = mean_squared_error(perm_core,fk_fit)\n",
    "rmse_Core_FK = np.sqrt(mse_Core_FK)\n",
    "mse_Core_Predict = mean_squared_error(perm_core,perm_predict)\n",
    "rmse_Core_Predict = np.sqrt(mse_Core_Predict)\n",
    "print('*  Core_Fit: %.4f RMSE' % (rmse_Core_Fit))\n",
    "print('*  Core_FK: %.4f RMSE' % (rmse_Core_FK))\n",
    "print('*  Core_Predict: %.4f RMSE' % (rmse_Core_Predict))\n",
    "\n",
    "mae_Core_Fit = mean_absolute_error(perm_core,perm_fit)\n",
    "print('*  Core_Fit: %.4f MAE' % (mae_Core_Fit))\n",
    "mae_Core_FK = mean_absolute_error(perm_core,fk_fit)\n",
    "print('*  Core_FK: %.4f MAE' % (mae_Core_FK))\n",
    "mae_Core_Predict = mean_absolute_error(perm_core,perm_predict)\n",
    "print('*  Core_Predict: %.4f MAE' % (mae_Core_Predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6255ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_Fitr2 = r2_score(perm_core,perm_fit)\n",
    "Core_Predictr2 = r2_score(perm_core,perm_predict)\n",
    "print(\"Core_Fitr2 score:\", r2_score(perm_core,perm_fit))\n",
    "print(\"Core_FK score:\", r2_score(perm_core,fk_fit))\n",
    "print(\"Core_Predictr2 score:\", r2_score(perm_core,perm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "figsize = 6, 6\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "plt.scatter(perm_core,perm_fit,s=80, c=\"r\",marker='o',label='Por-K Model(R\\u00b2=0.182)',edgecolors='black',linewidths=1,alpha=1) \n",
    "plt.scatter(perm_core,fk_fit,s=80, c=\"fuchsia\",marker='o',label='F-K Model(R\\u00b2=-0.070)',edgecolors='black',linewidths=1,alpha=1)  \n",
    "plt.scatter(perm_core,perm_predict,s=80, c=\"b\",marker='o',label='LGB-WOA(R\\u00b2=0.797)',edgecolors='black',linewidths=1,alpha=1)  \n",
    "#plt.grid()  #\n",
    "plt.xlim(0.01,1000)\n",
    "plt.ylim(0.01,1000)\n",
    "plt.yscale('log')#\n",
    "plt.xscale('log')#\n",
    "\n",
    "Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle='--',linewidth=2,color='black',label=\"Y=X\")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "plt.xlabel(\"Measured K(mD)\",fontproperties=\"Times New Roman\",fontsize=20,weight='normal')\n",
    "plt.ylabel(\"Predicted K(mD)\",fontproperties=\"Times New Roman\",fontsize=20,weight='normal')\n",
    "\n",
    "font = {'family':'Times New Roman'  #'serif', \n",
    "#         ,'style':'italic'\n",
    "        ,'weight':'normal'  # 'normal' \n",
    "#         ,'color':'red'\n",
    "        ,'size':13\n",
    "       }\n",
    "plt.legend(loc = 'upper left'   \n",
    "           , prop = font\n",
    "           , markerscale = 1# \n",
    "           ,frameon = True\n",
    "           ,framealpha=1\n",
    "          ) \n",
    "\n",
    "plt.savefig('BlindTest17-1-2.jpg',dpi=1500, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b8d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43729200",
   "metadata": {},
   "source": [
    "# shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_WOA = LGBMRegressor(random_state=42,device = 'gpu',learning_rate=0.17,n_estimators =100,max_depth=6,feature_fraction =0.7,bagging_fraction=0.9)\n",
    "#rf_reg = SVC(C=c, random_state=1, kernel=kernel_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib as mpl\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44774d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb_reg_WOA.fit(X_boruta_train_lg,y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc869532",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(y_train_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17106ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(y_train_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677cce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.median(y_train_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_train_ys[y_train_ys.PERM==0.16731733].index.tolist()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd32de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(y_train_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_boruta_train_lg)\n",
    "expected_value = explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "# visualize the first prediction's explanation\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "shap.plots.waterfall(shap_values[184],max_display=11,show=False)\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') # \n",
    "    text.set_color('black') # \n",
    "    text.set_fontsize(15)\n",
    "plt.savefig('waterfall-median.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2242b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "   \n",
    "config = {\n",
    "    \"font.family\": \"Times New Roman\",  #\n",
    "    \"font.serif\": [\"Times New Roman\"],  # \n",
    "    \"font.size\": 20,  # \n",
    "    \"axes.unicode_minus\": False,\n",
    "    \"mathtext.fontset\": \"stix\",  # \n",
    "}\n",
    "plt.rcParams.update(config)\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.beeswarm(shap_values,max_display=11,show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) #\n",
    "plt.xlabel('SHAP value', fontsize=20)#\n",
    "plt.tight_layout() \n",
    "\n",
    "#\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') # \n",
    "    text.set_color('black') # \n",
    "    text.set_fontsize(20)\n",
    "plt.savefig('beeswarm1.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"font.family\": \"Times New Roman\",  # \n",
    "    \"font.serif\": [\"Times New Roman\"],  #\n",
    "    \"font.size\": 20,  \n",
    "    \"axes.unicode_minus\": False,\n",
    "    \"mathtext.fontset\": \"stix\",  #\n",
    "}\n",
    "plt.rcParams.update(config)\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.summary_plot(shap_values,X_boruta_train_lg, plot_type=\"bar\",max_display=11,show=False)\n",
    "plt.xlabel(\"Mean(|Shap Value|)\",fontproperties=\"Times New Roman\",fontsize=20)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) #\n",
    "\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "#\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal')\n",
    "    text.set_color('black') # \n",
    "plt.tight_layout() #\n",
    "plt.savefig('feature importance_bar.jpg', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169ec67",
   "metadata": {},
   "source": [
    "# scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e09281",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"POR_LOG\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) \n",
    "plt.xlabel('POR_LOG', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') \n",
    "    text.set_color('black') #\n",
    "plt.tight_layout() \n",
    "plt.savefig('SCATTER-POR.jpg', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eed956",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"SH\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) \n",
    "plt.xlabel('SH', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') #\n",
    "    text.set_color('black') #\n",
    "plt.tight_layout() #\n",
    "plt.savefig('SCATTER-SH.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"KJ\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=15) #\n",
    "plt.yticks(fontproperties='Times New Roman', size=15) \n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('bold') \n",
    "    text.set_color('black') #\n",
    "plt.tight_layout() \n",
    "plt.savefig('SCATTER-KJ.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"P16H\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) #\n",
    "plt.xlabel('P16H', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') \n",
    "    text.set_color('black') # \n",
    "plt.tight_layout() \n",
    "plt.savefig('SCATTER-P16H.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94190bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"GR\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) #\n",
    "plt.xlabel('POR_LOG', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "#\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') \n",
    "    text.set_color('black') #\n",
    "plt.tight_layout() #\n",
    "plt.savefig('SCATTER-GR.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76531f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"DEN\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) #\n",
    "plt.yticks(fontproperties='Times New Roman', size=20) \n",
    "plt.xlabel('DEN', fontsize=20)\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') #\n",
    "    text.set_color('black') # \n",
    "plt.tight_layout() #\n",
    "plt.savefig('SCATTER-DEN.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e948021",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"CAL\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) \n",
    "plt.xlabel('CAL', fontsize=20)\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "#\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') # \n",
    "    text.set_color('black') # \n",
    "plt.tight_layout() #\n",
    "plt.savefig('SCATTER-CAL.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "#plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "#plt.rcParams['font.family'] = ['sans-serif']\n",
    "shap.plots.scatter(shap_values[:,\"CNL\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) #\n",
    "plt.yticks(fontproperties='Times New Roman', size=20) #\n",
    "plt.xlabel('CNL', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') # \n",
    "    text.set_color('black') # \n",
    "plt.tight_layout() #\n",
    "plt.savefig('SCATTER-CNL.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75802e37",
   "metadata": {},
   "source": [
    "# Simple dependence plot ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "config = {\n",
    "    \"font.size\": 20,  # 五号，10.5磅\n",
    "    \"axes.unicode_minus\": False,\n",
    "}\n",
    "plt.rcParams.update(config)\n",
    "plt.rcParams.update(config)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "shap.plots.scatter(shap_values[:,\"POR_LOG\"], color=shap_values[:,\"KJ\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) #\n",
    "plt.yticks(fontproperties='Times New Roman', size=20) \n",
    "plt.xlabel('POR_LOG', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') \n",
    "    text.set_color('black') #\n",
    "    text.set_fontsize(20)\n",
    "plt.tight_layout() #\n",
    "plt.savefig('KJ-POR.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf0c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "shap.plots.scatter(shap_values[:,\"POR_LOG\"], color=shap_values[:,\"P16H\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) #\n",
    "plt.yticks(fontproperties='Times New Roman', size=20) #\n",
    "plt.xlabel('POR_LOG', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') \n",
    "    text.set_color('black') # \n",
    "    text.set_fontsize(20)\n",
    "plt.tight_layout() #\n",
    "plt.savefig('P16H-POR.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "shap.plots.scatter(shap_values[:,\"POR_LOG\"], color=shap_values[:,\"DEN\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) #\n",
    "plt.yticks(fontproperties='Times New Roman', size=20) \n",
    "plt.xlabel('POR_LOG', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') \n",
    "    text.set_color('black') #\n",
    "    text.set_fontsize(20)\n",
    "plt.tight_layout() \n",
    "plt.savefig('DEN-POR.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "shap.plots.scatter(shap_values[:,\"POR_LOG\"], color=shap_values[:,\"CAL\"],show=False)\n",
    "plt.xticks( fontproperties='Times New Roman', size=20) \n",
    "plt.yticks(fontproperties='Times New Roman', size=20) \n",
    "plt.xlabel('POR_LOG', fontsize=20)#\n",
    "plt.ylabel('SHAP Value', fontsize=20)#\n",
    "\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "#\n",
    "fig = plt.gcf()\n",
    "\n",
    "for text in fig.findobj(plt.Text):\n",
    "    text.set_fontweight('normal') # \n",
    "    text.set_color('black') #\n",
    "    text.set_fontsize(20)\n",
    "plt.tight_layout() #\n",
    "plt.savefig('CAL-POR.jpg', dpi=1500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669555a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
